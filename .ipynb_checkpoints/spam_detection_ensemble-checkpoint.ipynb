{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we built our model with Naive Bayes it actually did preety good job on several performance measures. Now let's look at how we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically in this notebook, we will take a look at the following techniques:\n",
    "\n",
    "* [BaggingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier)\n",
    "* [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "* [AdaBoostClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)\n",
    "\n",
    "Another really useful guide for ensemble methods can be found [in the documentation here](http://scikit-learn.org/stable/modules/ensemble.html).\n",
    "\n",
    "These ensemble methods use a combination of techniques:\n",
    "\n",
    "* **Bootstrap the data** passed through a learner (bagging).\n",
    "* **Subset the features** used for a learner (combined with bagging signifies the two random components of random forests).\n",
    "* **Ensemble learners** together in a way that allows those that perform best in certain areas to create the largest impact (boosting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So before moving on to the model building part let's finish up the data preprocessing part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "data_df = pd.read_table(\"smsspamcollection/SMSSpamCollection\", sep='\\t', header=None, names=['label', 'sms_message'])\n",
    "\n",
    "# mapping the labels\n",
    "data_df['label'] = data_df['label'].map({'ham':0, 'spam':1})\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split out the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['sms_message'], data_df['label'], \n",
    "                                                    test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the countvectorize method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# fit the training data and return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# only transform the testing data and return the matrix\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Process Looks Familiar...\n",
    "\n",
    "In general, there is a five step process that can be used each type you want to use a supervised learning method (which we actually used above):\n",
    "\n",
    "1. **Import** the model.\n",
    "2. **Instantiate** the model with the hyperparameters of interest.\n",
    "3. **Fit** the model to the training data.\n",
    "4. **Predict** on the test data.\n",
    "5. **Score** the model by comparing the predictions to the actual values.\n",
    "\n",
    "Follow the steps through this notebook to perform these steps using each of the ensemble methods: **BaggingClassifier**, **RandomForestClassifier**, and **AdaBoostClassifier**.\n",
    "\n",
    "> **Step 1**: First use the documentation to `import` all three of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 2:** Now that we have imported each of the classifiers, `instantiate` each with the hyperparameters.  In the upcoming, we will see how we can automate the process to finding the best hyperparameters.  For now, let's get comfortable with the process and our new algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate a BaggingClassifier with:\n",
    "# 200 weak learners (n_estimators) and everything else as default values\n",
    "bagging_clf = BaggingClassifier(n_estimators=200)\n",
    "\n",
    "# Instantiate a RandomForestClassifier with:\n",
    "# 200 weak learners (n_estimators) and everything else as default values\n",
    "rf_clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Instantiate an a AdaBoostClassifier with:\n",
    "# With 300 weak learners (n_estimators) and a learning_rate of 0.2\n",
    "adaboost_clf = AdaBoostClassifier(n_estimators=300, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 3:** Now that we have instantiated each of our models, `fit` them using the **training_data** and **y_train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.2, n_estimators=300, random_state=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit your BaggingClassifier to the training data\n",
    "bagging_clf.fit(training_data, y_train)\n",
    "\n",
    "# Fit your RandomForestClassifier to the training data\n",
    "rf_clf.fit(training_data, y_train)\n",
    "\n",
    "# Fit your AdaBoostClassifier to the training data\n",
    "adaboost_clf.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 4:** Now that we have fit each of your models, we will use each to `predict` on the **testing_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict using BaggingClassifier on testing_data\n",
    "bagging_pred = bagging_clf.predict(testing_data)\n",
    "\n",
    "# predict using RandomForestClassifier on testing data\n",
    "rf_pred = rf_clf.predict(testing_data)\n",
    "\n",
    "# predict using AdaBoostClassifier on testing data\n",
    "adaboost_pred = adaboost_clf.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 5:** Now that we have made your predictions, compare our predictions to the actual values using the function below for each of your models - this will give us the `score` for how well each of our models is performing.  It might also be useful to show the naive bayes model again here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Instantiate our naivebayes model\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# Fit our model to the training data\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_metrics(y_true, preds, model_name=None):\n",
    "    '''\n",
    "    INPUT:\n",
    "    y_true - the y values that are actually true in the dataset (numpy array or pandas series)\n",
    "    preds - the predictions for those values from some model (numpy array or pandas series)\n",
    "    model_name - (str - optional) a name associated with the model if you would like to add it to the print statements \n",
    "    \n",
    "    OUTPUT:\n",
    "    None - prints the accuracy, precision, recall, and F1 score\n",
    "    '''\n",
    "    if model_name == None:\n",
    "        print('Accuracy score: ', format(accuracy_score(y_true, preds)))\n",
    "        print('Precision score: ', format(precision_score(y_true, preds)))\n",
    "        print('Recall score: ', format(recall_score(y_true, preds)))\n",
    "        print('F1 score: ', format(f1_score(y_true, preds)))\n",
    "        print('\\n\\n')\n",
    "    else:\n",
    "        print('Accuracy score for ' + model_name + ' :' , format(accuracy_score(y_true, preds)))\n",
    "        print('Precision score ' + model_name + ' :', format(precision_score(y_true, preds)))\n",
    "        print('Recall score ' + model_name + ' :', format(recall_score(y_true, preds)))\n",
    "        print('F1 score ' + model_name + ' :', format(f1_score(y_true, preds)))\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Bagging : 0.9763101220387652\n",
      "Precision score Bagging : 0.9322033898305084\n",
      "Recall score Bagging : 0.8870967741935484\n",
      "F1 score Bagging : 0.9090909090909092\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Random Forest : 0.9784637473079684\n",
      "Precision score Random Forest : 1.0\n",
      "Recall score Random Forest : 0.8387096774193549\n",
      "F1 score Random Forest : 0.9122807017543859\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for AdaBoost : 0.9784637473079684\n",
      "Precision score AdaBoost : 0.975609756097561\n",
      "Recall score AdaBoost : 0.8602150537634409\n",
      "F1 score AdaBoost : 0.9142857142857143\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Naive Bayes : 0.9885139985642498\n",
      "Precision score Naive Bayes : 0.9775280898876404\n",
      "Recall score Naive Bayes : 0.9354838709677419\n",
      "F1 score Naive Bayes : 0.956043956043956\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Bagging scores\n",
    "print_metrics(y_test, bagging_pred, 'Bagging')\n",
    "\n",
    "# Print Random Forest scores\n",
    "print_metrics(y_test, rf_pred, 'Random Forest')\n",
    "\n",
    "# Print AdaBoost scores\n",
    "print_metrics(y_test, adaboost_pred, 'AdaBoost')\n",
    "\n",
    "# Naive Bayes Classifier scores\n",
    "print_metrics(y_test, predictions, 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
